{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7fe7781a6458>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Add REAL WORLD configuration and camera\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../scenarios/check.g\")\n",
    "\n",
    "#obj1 = RealWorld.frame(\"obj1\")\n",
    "#obj1.setColor([1.,.0,.0])\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ry.Config()\n",
    "C.addFile('../scenarios/check.g')\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percept = C.addFrame(\"percept\")\n",
    "# percept.setQuaternion([1,0,0,0])\n",
    "# percept.setShape(ry.ST.sphere, [.03])\n",
    "# percept.setColor([0,1,0])\n",
    "# percept.setPosition([0,0,2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.recopyMeshes(C)\n",
    "V.setConfiguration(C)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = RealWorld.frame(\"tire\")\n",
    "obj.setContact(1)\n",
    "obj.getPosition()\n",
    "\n",
    "car = RealWorld.frame(\"car\")\n",
    "#car.setContact(1)\n",
    "\n",
    "# obj.setColor([0.,1.,.0])\n",
    "# obj.setPosition([0., 0, 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tire', 'ID': 164, 'shape': 'cylinder', 'size': [0.15, 0.3], 'color': [0.0, 0.0, 0.0], 'contact': 1, 'mass': 42.4115008234622, 'X': [2.0, -1.1, 0.73, -0.741170883, -0.000267996453, 1.97769841e-05, 0.671316564]}\n",
      "[-7.41170883e-01 -2.67996453e-04  1.97769841e-05  6.71316564e-01]\n"
     ]
    }
   ],
   "source": [
    "print(obj.info())\n",
    "print(obj.getQuaternion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_position(gipper, position):\n",
    "    komo = C.komo_path(1.,1, tau, True) \n",
    "    komo.clearObjectives()\n",
    "    komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq);\n",
    "    komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq);\n",
    "    komo.addObjective([1.], ry.FS.position, [gipper], ry.OT.sos, [1e3], target=position)\n",
    "    komo.addObjective([], ry.FS.quaternion, [gipper], ry.OT.sos, [1e3], target=[0, 0, 0.7068252, 0.7073883])\n",
    "    komo.optimize()\n",
    "    return komo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_object(gripper, obj):\n",
    "    komo = C.komo_path(1.,1, tau, True) \n",
    "    komo.clearObjectives()\n",
    "    komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq);\n",
    "    komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq);\n",
    "    komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripperCenter\",t_object], ry.OT.eq, [1e2])\n",
    "    komo.addObjective([1.], ry.FS.scalarProductXZ, [t_object, \"R_gripperCenter\"], ry.OT.eq, target=[1])\n",
    "    komo.addObjective([1.], ry.FS.scalarProductYZ, [\"R_gripperCenter\", t_object], ry.OT.eq)\n",
    "    komo.addObjective(time=[1.], feature=ry.FS.qItself, type=ry.OT.eq, order=1);\n",
    "    komo.addObjective([], ry.FS.qItself, [\"R_finger1\"], ry.OT.eq, [1e1], order=1)\n",
    "    komo.addObjective([], ry.FS.qItself, [\"R_finger2\"], ry.OT.eq, [1e1], order=1)\n",
    "    komo.optimize()\n",
    "    return komo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.659706821303137e-09\n",
      "graspping 24\n",
      "-5.659706821303137e-09\n",
      "opening\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "t_object = \"tire\"\n",
    "closed = 0\n",
    "\n",
    "target_pos = np.array([1.16, -0.75, 1])\n",
    "for t in range(500):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "\n",
    "    V.recopyMeshes(C)\n",
    "    V.setConfiguration(C)\n",
    "    \n",
    "    p_obj = obj.getPosition()\n",
    "    \n",
    "    if not S.getGripperIsGrasping(\"R_gripper\"):\n",
    "        [y,J] = C.evalFeature(ry.distance, [\"R_gripperCenter\", t_object])\n",
    "        #print(abs(y))\n",
    "        if abs(y) < 0.04 and closed == 0:\n",
    "            closed = 1\n",
    "            print(S.getGripperWidth(\"R_gripper\"))\n",
    "            S.closeGripper(\"R_gripper\")\n",
    "            #t_object = \"object1\"\n",
    "            print(\"graspping\", t)\n",
    "            print(S.getGripperWidth(\"R_gripper\"))\n",
    "            \n",
    "    else:\n",
    "        #print(\"while closing \",S.getGripperWidth(\"R_gripper\"))\n",
    "        [y,J] = C.evalFeature(ry.FS.position, [\"R_gripperCenter\"])\n",
    "        distance = np.linalg.norm(y-target_pos)\n",
    "        if distance < 0.05 and closed == 1:\n",
    "            S.openGripper(\"R_gripper\")\n",
    "            print(\"opening\")\n",
    "            closed = 2\n",
    "        # add a grasping condition\n",
    "        # and utilize\n",
    "        # S.closeGripper(\"R_gripper\")\n",
    "\n",
    "    # you can add your manipulation code here\n",
    "    # Tips, not restricted: compute a one-step komo path\n",
    "    # and compute the configuration q\n",
    "    # komo = C.komo_path(1.,1,tau,True)\n",
    "\n",
    "    if closed == 0:\n",
    "        komo = move_to_object(\"R_gripperCenter\", t_object)\n",
    "    elif closed == 1 and S.getGripperIsGrasping(\"R_gripper\"):\n",
    "        komo = move_to_position(\"R_gripperCenter\", target_pos)\n",
    "    \n",
    "    if closed != 2:\n",
    "        C.setFrameState( komo.getConfiguration(0))\n",
    "        #V.setConfiguration(C)\n",
    "        q = C.getJointState()\n",
    "    \n",
    "    S.step(q, tau, ry.ControlMode.position)\n",
    "    \n",
    "    #S.closeGripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16000563 -0.75000968  0.99999634]\n",
      "1.1779579148354401e-05\n"
     ]
    }
   ],
   "source": [
    "[y,J] = C.evalFeature(ry.FS.position, [\"R_gripperCenter\"])\n",
    "print(y)\n",
    "distance = np.linalg.norm(y-target_pos)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----ccopied---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2398753713582315e-14\n",
      "graspping 15\n",
      "-1.2398753713582315e-14\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "t_object = \"tire\"\n",
    "closed = 0\n",
    "for t in range(800):\n",
    "    time.sleep(0.001)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "\n",
    "    V.recopyMeshes(C)\n",
    "    V.setConfiguration(C)\n",
    "    \n",
    "    p_obj = obj.getPosition()\n",
    "    \n",
    "    if not S.getGripperIsGrasping(\"R_gripper\"):\n",
    "        [y,J] = C.evalFeature(ry.distance, [\"R_gripperCenter\", t_object])\n",
    "        #print(abs(y))\n",
    "        if abs(y) < 0.1 and closed == 0:\n",
    "            closed = 1\n",
    "            print(S.getGripperWidth(\"R_gripper\"))\n",
    "            S.closeGripper(\"R_gripper\")\n",
    "            #t_object = \"object1\"\n",
    "            print(\"graspping\", t)\n",
    "            print(S.getGripperWidth(\"R_gripper\"))\n",
    "            \n",
    "    else:\n",
    "        #print(\"while closing \",S.getGripperWidth(\"R_gripper\"))\n",
    "        t_object = \"L_gripperCenter\"\n",
    "        [y,J] = C.evalFeature(ry.distance, [\"R_gripperCenter\", t_object])\n",
    "        if abs(y) < 0.2 and closed == 1:\n",
    "            S.openGripper(\"R_gripper\")\n",
    "            print(\"opening\")\n",
    "            closed = 2\n",
    "        # add a grasping condition\n",
    "        # and utilize\n",
    "        # S.closeGripper(\"R_gripper\")\n",
    "\n",
    "    # you can add your manipulation code here\n",
    "    # Tips, not restricted: compute a one-step komo path\n",
    "    # and compute the configuration q\n",
    "    # komo = C.komo_path(1.,1,tau,True)\n",
    "\n",
    "    if closed != 2 :\n",
    "        komo = C.komo_path(1.,1, tau, True) \n",
    "        komo.clearObjectives()\n",
    "        komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq);\n",
    "        komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq);\n",
    "        komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripperCenter\",t_object], ry.OT.eq, [1e2])\n",
    "        \n",
    "        if closed == 0:\n",
    "            komo.addObjective([1.], ry.FS.scalarProductXZ, [t_object, \"R_gripperCenter\"], ry.OT.eq, target=[1])\n",
    "            komo.addObjective([1.], ry.FS.scalarProductYZ, [\"R_gripperCenter\", t_object], ry.OT.eq)\n",
    "\n",
    "        komo.addObjective(time=[1.], feature=ry.FS.qItself, type=ry.OT.eq, order=1);\n",
    "        komo.addObjective([], ry.FS.qItself, [\"R_finger1\"], ry.OT.eq, [1e1], order=1)\n",
    "        komo.addObjective([], ry.FS.qItself, [\"R_finger2\"], ry.OT.eq, [1e1], order=1)\n",
    "        komo.optimize()\n",
    "        #komo.getReport()\n",
    "        C.setFrameState( komo.getConfiguration(0))\n",
    "        #V.setConfiguration(C)\n",
    "        q = C.getJointState()  \n",
    "\n",
    "    S.step(q, tau, ry.ControlMode.position)\n",
    "    #S.closeGripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "/home/vijay/Desktop/practical-robotics/robotics-course/rai/rai/Core/util.cpp:cd_file:1143(-2) couldn't change to directory '../../scenarios' from '/home/vijay/Desktop/practical-robotics/robotics-course/frames_check'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88f19deb8432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#D = C.view() #rather use the ConfiguratioViewer below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../scenarios/pandasTable.g\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: /home/vijay/Desktop/practical-robotics/robotics-course/rai/rai/Core/util.cpp:cd_file:1143(-2) couldn't change to directory '../../scenarios' from '/home/vijay/Desktop/practical-robotics/robotics-course/frames_check'"
     ]
    }
   ],
   "source": [
    "#-- MODEL WORLD configuration, this is the data structure on which you represent\n",
    "# what you know about the world and compute things (controls, contacts, etc)\n",
    "C = ry.Config()\n",
    "#D = C.view() #rather use the ConfiguratioViewer below\n",
    "C.addFile(\"../../scenarios/pandasTable.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- using the viewer, you can view configurations or paths\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "/home/vijay/Desktop/practical-robotics/robotics-course/rai/rai/Kin/TM_default.cpp:phi:103(-2) CHECK failed: 'a' -- ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-11b39afb575a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetJointState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#set your robot model to match the real q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#to update your model display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"R_gripper\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /home/vijay/Desktop/practical-robotics/robotics-course/rai/rai/Kin/TM_default.cpp:phi:103(-2) CHECK failed: 'a' -- "
     ]
    }
   ],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "for t in range(5):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    [y,J] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ [0.,0.,-1e-1];\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing things relative to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new frame to the MODEL configuration\n",
    "# (Perception will later have to do exactly this: add perceived objects to the model)\n",
    "capsule = C.addFrame(\"capsule\")\n",
    "box     = C.addFrame(\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame parameters, associate a shape to the frame, \n",
    "#capsule.setPosition([.8,0,1.5])\n",
    "#capsule.setPosition([0.1,-0.75,1.25])\n",
    "#capsule.setQuaternion([1,0,.5,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rect_Center = [-0.3,0.4,1.5]\n",
    "Rect_Width  = 0.4\n",
    "Rect_Height = 0.2\n",
    "Rect_Start  = [(Rect_Center[0] - Rect_Width/2), Rect_Center[1]-0.1, (Rect_Center[2] + Rect_Height/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capsule.setPosition([0.3,0,0.8])\n",
    "capsule.setPosition([-0.1,0.2,1.5])\n",
    "capsule.setQuaternion([1,0,0,0])\n",
    "\n",
    "capsule.setShape(ry.ST.capsule, [.2,.02])\n",
    "capsule.setColor([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "box.setPosition(Rect_Center)\n",
    "box.setQuaternion([1,0,0,0])\n",
    "box.setShape(ry.ST.box, [Rect_Width,0.05,Rect_Height])\n",
    "box.setColor([1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.setConfiguration(C)\n",
    "#V.recopyMeshes(C) #this is rarely necessary, only when you change meshes within C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectCollision(C):\n",
    "    collisionPresent = False\n",
    "    coll = C.feature(ry.FS.accumulatedCollisions, [])\n",
    "    C.computeCollisions()\n",
    "    coll.eval(C)\n",
    "    Collisions = C.getCollisions(0)\n",
    "    if len(Collisions) > 0:\n",
    "        for i in Collisions:\n",
    "            if ('L_' in i[0] and 'R_' in i[1]) or ('R_' in i[0] and 'L_' in i[1]):\n",
    "                print(i)\n",
    "                collisionPresent = True\n",
    "    return collisionPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 0\n",
    "\n",
    "def DrawRectangle(Rect_Pos):\n",
    "    global state\n",
    "    \n",
    "    if state == 0:\n",
    "        Rect_Pos =  Rect_Start\n",
    "    elif state == 1:\n",
    "        Rect_Pos[0] += Rect_Width\n",
    "    elif state == 2:\n",
    "        Rect_Pos[2] -= Rect_Height\n",
    "    elif state == 3:\n",
    "        Rect_Pos[0] -= Rect_Width\n",
    "    elif state == 4:\n",
    "        Rect_Pos[2] += Rect_Height\n",
    "        \n",
    "    state = (state+1) % 5\n",
    "    return Rect_Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('L_panda_coll7', 'R_finger2', -0.00013082130226798813)\n",
      "Possible Chance of Collision...Terminating\n"
     ]
    }
   ],
   "source": [
    "iteration = 5000\n",
    "tau = .01\n",
    "y_box = np.zeros(3)\n",
    "align = True\n",
    "Rect_Pos = Rect_Start\n",
    "\n",
    "\n",
    "[y_itself ,J_itself]  = C.evalFeature(ry.FS.position, [\"L_lift\"])\n",
    "[y_GripInit ,J_GripInit]  = C.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "\n",
    "\n",
    "#-- the following is the simulation loop\n",
    "for t in range(iteration):\n",
    "    y = []\n",
    "    J = []\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    \n",
    "    # position difference between Right gripper and the capsule\n",
    "    [y_capsule,J_capsule] = C.evalFeature(ry.FS.positionDiff, [\"R_gripperCenter\", \"capsule\"])\n",
    "    \n",
    "    # position difference between Left gripper and the box \n",
    "    #[y_box    ,J_box]     = C.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"capsule\"])\n",
    "    [y_GripCen    ,J_GripCen]     = C.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "    \n",
    "    #y_target = y_GripInit + ((t+1)/iteration) * (Rect_Center - y_GripInit)\n",
    "    # Draw Rectangle\n",
    "    \n",
    "    if(np.linalg.norm(y_box)) < 5e-2:\n",
    "        Rect_Pos = DrawRectangle(Rect_Pos)\n",
    "    \n",
    "    y_box = y_GripCen - Rect_Pos\n",
    "    \n",
    "        \n",
    "    # Make Right gripper parallel to Y axis by making orthogonal to other 2 directions\n",
    "    [y_capZZ, J_capsuleZZ] = C.evalFeature(ry.FS.scalarProductZZ, [\"R_gripperCenter\", \"capsule\"])\n",
    "    [y_capXZ, J_capsuleXZ] = C.evalFeature(ry.FS.scalarProductXZ, [\"R_gripperCenter\", \"capsule\"])\n",
    "    \n",
    "    [y_LGrip  ,J_LGrip]   = C.evalFeature(ry.FS.position, [\"L_lift\"])\n",
    "    \n",
    "    # reach capsule\n",
    "    y = y_capsule/tau\n",
    "    J = J_capsule/tau\n",
    "    \n",
    "    \n",
    "    if align == True:\n",
    "        # make left gripper parallel to Rectangle boundaries\n",
    "        [y_RectZZ, J_RectZZ] = C.evalFeature(ry.FS.scalarProductZZ, [\"box\", \"L_gripperCenter\"])\n",
    "        [y_RectXZ, J_RectXZ] = C.evalFeature(ry.FS.scalarProductXZ, [\"L_gripperCenter\", \"box\"])\n",
    "        \n",
    "        # merge tasks for gripper handle parallel to rectangle\n",
    "        y  = np.concatenate((y ,y_RectZZ/tau,y_RectXZ/tau))\n",
    "        J = np.vstack((J, J_RectZZ/tau, J_RectXZ/tau))\n",
    "\n",
    "    # stay close to initial position\n",
    "    y  = np.concatenate((y ,  (y_LGrip - y_itself)))\n",
    "    J = np.vstack((J,  J_LGrip))    \n",
    "\n",
    "    # merge all tasks\n",
    "    y  = np.concatenate((y , y_capZZ/tau, y_capXZ/tau, y_box/tau))\n",
    "    J = np.vstack((J,  J_capsuleZZ/tau, J_capsuleXZ/tau, J_GripCen/tau))\n",
    "    \n",
    "    CollStatus = DetectCollision(C)\n",
    "    \n",
    "    if CollStatus == True:\n",
    "        print(\"Possible Chance of Collision...Terminating\")\n",
    "        break\n",
    "    \n",
    "    # calculate joint velocities\n",
    "    psudeoInverseJ = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0]))\n",
    "    vel =  psudeoInverseJ @ (-y)\n",
    "    \n",
    "    # Directly stop Left gripper lifting\n",
    "    vel[0] = 0\n",
    "    \n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you align the gripper for a proper grasp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=0\n",
    "V=0\n",
    "C=0\n",
    "RealWorld=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct inverse Kinematics with multiple objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7f327898aae8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ry.Config()\n",
    "C.addFile(\"../../scenarios/pandasTable.g\")\n",
    "\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7d7681224da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetJointState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#set your robot model to match the real q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#to update your model display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#evaluate a first feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "\n",
    "    #evaluate a first feature\n",
    "    [y1,J1] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    #redefine y1 to become the desired change-of-value (\"error\" or \"residual\"); here just a constant velocity\n",
    "    y1 = np.array([0.,0.,-1e-1])\n",
    "    #you can multiply y1 and J1 here with some number, to increase the importance of the first feature\n",
    "    \n",
    "    #evaluate a second feature\n",
    "    [y2,J2] = C.evalFeature(ry.FS.scalarProductYZ, [\"R_gripper\",\"world\"])\n",
    "    #redefine y2 to become the desired change-of-value (\"error\" or \"residual\"); here by subtracting the target\n",
    "    y2 = [1.] - y2\n",
    "    #you can multiply y2 and J2 here with some number, to increase the importance of the second feature\n",
    "\n",
    "    #stack all tasks\n",
    "    y = np.block([y1, y2])\n",
    "    J = np.block([[J1],[J2]])\n",
    "    \n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ y;\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.getJointNames()\n",
    "Rect_Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null space motion \n",
    "#delA = np.ones(17) * 0.1\n",
    "#delA[0]=delA[-1] = delA[8] = 0\n",
    "#vel =  psudeoInverseJ @ (-y) + (np.eye(17) - psudeoInverseJ @ J) @ delA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#-- the following is the simulation loop\\ntau = .01\\n\\n#[y_itself ,J_itself]  = C.evalFeature(ry.FS.position, [\"L_gripper\"])\\n\\nfor t in range(500):\\n    y = []\\n    J = []\\n    time.sleep(0.01)\\n\\n    #grab sensor readings from the simulation\\n    q = S.get_q()\\n    if t%10 == 0:\\n            [rgb, depth] = S.getImageAndDepth()  #we don\\'t need images with 100Hz, rendering is slow\\n\\n    #some good old fashioned IK\\n    C.setJointState(q) #set your robot model to match the real q\\n    V.setConfiguration(C) #to update your model display\\n    \\n    [y_capsule,J_capsule] = C.evalFeature(ry.FS.positionDiff, [\"R_gripperCenter\", \"capsule\"])\\n    #[y_box    ,J_box]     = C.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"box\"])\\n    #[y_LGrip  ,J_LGrip]   = C.evalFeature(ry.FS.position, [\"L_gripper\"])\\n\\n    [y_capZZ, J_capsuleZZ] = C.evalFeature(ry.FS.scalarProductZZ, [\"R_gripperCenter\", \"capsule\"])\\n    [y_capXZ, J_capsuleXZ] = C.evalFeature(ry.FS.scalarProductXZ, [\"R_gripperCenter\", \"capsule\"])\\n    \\n    # merge all tasks\\n    \\n    # reach capsule\\n    y = y_capsule/tau\\n    J = J_capsule/tau\\n    \\n    # stay close to initial position\\n    #y  = np.concatenate((y ,  (y_LGrip - y_itself)))\\n    #J = np.vstack((J,  J_LGrip))    \\n    \\n    # reach box\\n    y  = np.concatenate((y , y_capZZ/tau, y_capXZ/tau, y_box/tau))\\n    J = np.vstack((J,  J_capsuleZZ/tau, J_capsuleXZ/tau, J_box/tau))\\n    \\n    psudeoInverseJ = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0]))\\n    \\n    vel =  psudeoInverseJ @ (-y)\\n    \\n    # stop Left gripper lifting\\n    vel[0] = 0\\n    \\n    #send velocity controls to the simulation\\n    S.step(vel, tau, ry.ControlMode.velocity)\\n'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code with Left gripper picking up object\n",
    "# currently not used\n",
    "\n",
    "'''\n",
    "\n",
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "#[y_itself ,J_itself]  = C.evalFeature(ry.FS.position, [\"L_gripper\"])\n",
    "\n",
    "for t in range(500):\n",
    "    y = []\n",
    "    J = []\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    \n",
    "    [y_capsule,J_capsule] = C.evalFeature(ry.FS.positionDiff, [\"R_gripperCenter\", \"capsule\"])\n",
    "    #[y_box    ,J_box]     = C.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"box\"])\n",
    "    #[y_LGrip  ,J_LGrip]   = C.evalFeature(ry.FS.position, [\"L_gripper\"])\n",
    "\n",
    "    [y_capZZ, J_capsuleZZ] = C.evalFeature(ry.FS.scalarProductZZ, [\"R_gripperCenter\", \"capsule\"])\n",
    "    [y_capXZ, J_capsuleXZ] = C.evalFeature(ry.FS.scalarProductXZ, [\"R_gripperCenter\", \"capsule\"])\n",
    "    \n",
    "    # merge all tasks\n",
    "    \n",
    "    # reach capsule\n",
    "    y = y_capsule/tau\n",
    "    J = J_capsule/tau\n",
    "    \n",
    "    # stay close to initial position\n",
    "    #y  = np.concatenate((y ,  (y_LGrip - y_itself)))\n",
    "    #J = np.vstack((J,  J_LGrip))    \n",
    "    \n",
    "    # reach box\n",
    "    y  = np.concatenate((y , y_capZZ/tau, y_capXZ/tau, y_box/tau))\n",
    "    J = np.vstack((J,  J_capsuleZZ/tau, J_capsuleXZ/tau, J_box/tau))\n",
    "    \n",
    "    psudeoInverseJ = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0]))\n",
    "    \n",
    "    vel =  psudeoInverseJ @ (-y)\n",
    "    \n",
    "    # stop Left gripper lifting\n",
    "    vel[0] = 0\n",
    "    \n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
