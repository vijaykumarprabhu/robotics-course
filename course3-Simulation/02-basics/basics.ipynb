{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import libry as ry\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- REAL WORLD configuration, which is attached to the physics engine\n",
    "# accessing this directly would be cheating!\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- MODEL WORLD configuration, this is the data structure on which you represent\n",
    "# what you know about the world and compute things (controls, contacts, etc)\n",
    "C = ry.Config()\n",
    "#D = C.view() #rather use the ConfiguratioViewer below\n",
    "C.addFile(\"../../scenarios/pandasTable.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- using the viewer, you can view configurations or paths\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "for t in range(5):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    [y,J] = C.evalFeature(ry.FS.position, [\"R_gripper\"])\n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ [0.,0.,-1e-1];\n",
    "\n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doing things relative to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new frame to the MODEL configuration\n",
    "# (Perception will later have to do exactly this: add perceived objects to the model)\n",
    "capsule = C.addFrame(\"capsule\")\n",
    "box     = C.addFrame(\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frame parameters, associate a shape to the frame, \n",
    "capsule.setPosition([.8,0,1.5])\n",
    "capsule.setQuaternion([1,0,.5,0])\n",
    "capsule.setShape(ry.ST.capsule, [.2,.02])\n",
    "capsule.setColor([1,0,1])\n",
    "\n",
    "\n",
    "box.setPosition([-.8,0,1.5])\n",
    "box.setQuaternion([1,0,.5,0])\n",
    "box.setShape(ry.ST.box, [0.1,0.1,0.1])\n",
    "box.setColor([1,1,0])\n",
    "\n",
    "\n",
    "V.setConfiguration(C)\n",
    "#V.recopyMeshes(C) #this is rarely necessary, only when you change meshes within C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- the following is the simulation loop\n",
    "tau = .01\n",
    "\n",
    "#[y_itself ,J_itself]  = C.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "\n",
    "for t in range(500):\n",
    "    y = []\n",
    "    J = []\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "            [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "\n",
    "    #some good old fashioned IK\n",
    "    C.setJointState(q) #set your robot model to match the real q\n",
    "    V.setConfiguration(C) #to update your model display\n",
    "    \n",
    "    [y_capsule,J_capsule] = C.evalFeature(ry.FS.positionDiff, [\"R_gripperCenter\", \"capsule\"])\n",
    "    [y_box    ,J_box]     = C.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"box\"])\n",
    "    [y_LGrip  ,J_LGrip]   = C.evalFeature(ry.FS.position, [\"L_gripperCenter\"])\n",
    "        \n",
    "    # merge all tasks\n",
    "    \n",
    "    # reach capsule\n",
    "    y = y_capsule\n",
    "    J = J_capsule\n",
    "    \n",
    "    # stay close to initial position\n",
    "    #y  = np.concatenate((y ,  (y_LGrip - y_itself)))\n",
    "    #J = np.vstack((J,  J_LGrip))\n",
    "    \n",
    "    # reach box\n",
    "    y  = np.concatenate((y ,  y_box/tau))\n",
    "    J = np.vstack((J,  J_box/tau))\n",
    "    \n",
    "    vel = J.T @ np.linalg.inv(J@J.T + 1e-2*np.eye(y.shape[0])) @ (-y);\n",
    "    \n",
    "    # stop Left gripper lifting\n",
    "    vel[0] = 0\n",
    "    \n",
    "    #send velocity controls to the simulation\n",
    "    S.step(vel, tau, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you align the gripper for a proper grasp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=0\n",
    "V=0\n",
    "C=0\n",
    "RealWorld=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.20530195e-03,  8.32129104e-04,  7.37533044e-03,  2.65195821e-03,\n",
       "        2.91730930e-03,  5.43299331e-04,  4.19913932e-03, -5.33468827e-09,\n",
       "        0.00000000e+00, -9.93030449e-04,  1.08702300e-02, -3.96479269e-03,\n",
       "        7.57881804e-03, -5.53363185e-04,  7.43794935e-03, -6.42306208e-09,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
