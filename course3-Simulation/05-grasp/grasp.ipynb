{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's edit the real world before we create the simulation\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/challenge.g\")\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting obj5\n",
      "deleting obj6\n",
      "deleting obj7\n",
      "deleting obj8\n",
      "deleting obj9\n",
      "deleting obj10\n",
      "deleting obj11\n",
      "deleting obj12\n",
      "deleting obj13\n",
      "deleting obj14\n",
      "deleting obj15\n",
      "deleting obj16\n",
      "deleting obj17\n",
      "deleting obj18\n",
      "deleting obj19\n",
      "deleting obj20\n",
      "deleting obj21\n",
      "deleting obj22\n",
      "deleting obj23\n",
      "deleting obj24\n",
      "deleting obj25\n",
      "deleting obj26\n",
      "deleting obj27\n",
      "deleting obj28\n",
      "deleting obj29\n"
     ]
    }
   ],
   "source": [
    "#change some colors\n",
    "RealWorld.getFrame(\"obj0\").setColor([0,1,0])\n",
    "RealWorld.getFrame(\"obj1\").setColor([1,0,0])\n",
    "RealWorld.getFrame(\"obj2\").setColor([1,1,0])\n",
    "RealWorld.getFrame(\"obj3\").setColor([1,0,1])\n",
    "RealWorld.getFrame(\"obj4\").setColor([0,1,1])\n",
    "\n",
    "#you can also change the shape & size\n",
    "RealWorld.getFrame(\"obj0\").setColor([1.,0,0])\n",
    "RealWorld.getFrame(\"obj0\").setShape(ry.ST.sphere, [.03])\n",
    "#RealWorld.getFrame(\"obj0\").setShape(ry.ST.ssBox, [.05, .05, .2, .01])\n",
    "RealWorld.getFrame(\"obj0\").setPosition([0., .2, 2.])\n",
    "\n",
    "#remove some objects\n",
    "for o in range(5,30):\n",
    "    name = \"obj%i\" % o\n",
    "    print(\"deleting\", name)\n",
    "    RealWorld.delFrame(name)\n",
    "\n",
    "    \n",
    "V.recopyMeshes(RealWorld)\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7f79be1c6ae8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the simulation\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're adding an \"imp\" to the simulation, which is a little process that can inject perturbations\n",
    "S.addImp(ry.ImpType.objectImpulses, ['obj0'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model world\n",
    "C = ry.Config()\n",
    "C.addFile('../../scenarios/pandasTable.g')\n",
    "#V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(C)\n",
    "cameraFrame = C.frame(\"camera\")\n",
    "\n",
    "#the focal length\n",
    "f = 0.895\n",
    "f = f * 360.\n",
    "fxfypxpy = [f, f, 320., 180.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_ball(bgr):\n",
    "    \n",
    "    #if len(rgb)>0: cv.imshow('OPENCV - rgb', bgr)\n",
    "\n",
    "    hsv = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([0,120,70])\n",
    "    upper_red = np.array([10,255,255])\n",
    "\n",
    "    mask1 = cv.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # second red component\n",
    "    lower_red = np.array([170,120,70])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask2 = cv.inRange(hsv,lower_red,upper_red)\n",
    "\n",
    "\n",
    "    # combine mask ( + does or operation) to generate binary image with white as red color\n",
    "    mask = mask1 + mask2\n",
    "    if len(mask)>0: cv.imshow('OPENCV - binary', mask)\n",
    "\n",
    "    blur_mask = cv.GaussianBlur(mask,(9,9),3,3)\n",
    "\n",
    "#     weighted_mask = cv.addWeighted(mask1, 1.0, mask2, 1.0, 0.0)\n",
    "\n",
    "#     # then the result is blurred\n",
    "#     blurred_mask = cv.GaussianBlur(weighted_mask,(9,9),3,3)\n",
    "\n",
    "#     # some morphological operations (closing) to remove small blobs \n",
    "#     erode_element = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "#     dilate_element = cv.getStructuringElement(cv.MORPH_RECT, (8, 8))\n",
    "#     eroded_mask = cv.erode(blurred_mask,erode_element)\n",
    "#     dilated_mask = cv.dilate(eroded_mask,dilate_element)\n",
    "\n",
    "    circles = cv.HoughCircles(blur_mask, cv.HOUGH_GRADIENT, 1, 150, param1=100, param2=20, minRadius=0, maxRadius=13)\n",
    "    black_img = np.zeros(bgr.shape)\n",
    "    if circles is not None:\n",
    "        for circle in circles[0, :]:\n",
    "            circled_orig = cv.circle(black_img, (circle[0], circle[1]), circle[2], (255,255,255),thickness=-1)\n",
    "\n",
    "        #circled_orig_grey = cv.cvtColor(circled_orig, cv.COLOR_BGR2GRAY)\n",
    "        circled_orig_blur = cv.GaussianBlur(circled_orig[:,:,0],(3,3),3,3)\n",
    "        cv.imshow(\"circle_mask\", circled_orig_blur)\n",
    "        return circled_orig_blur\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = S.get_q()\n",
    "# [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "# segment_ball(rgb)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# komo = C.komo_path(1.,20, 5., True) \n",
    "\n",
    "# komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.ineq, [1e2])\n",
    "\n",
    "# komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripperCenter\", \"object\"], ry.OT.sos, [1e2],target=[0.05,0,0])\n",
    "# komo.addObjective([1.], ry.FS.positionDiff, [\"L_gripperCenter\", \"object\"], ry.OT.sos, [1e2],target=[0,0,0.1])\n",
    "\n",
    "# komo.addObjective([1.], ry.FS.scalarProductXZ, [\"object\", \"R_gripperCenter\"], ry.OT.eq, target=[1])\n",
    "# komo.addObjective([1.], ry.FS.scalarProductXZ, [\"R_gripperCenter\", \"object\"], ry.OT.eq)\n",
    "\n",
    "# komo.addObjective([1.], ry.FS.scalarProductYY, [\"L_gripperCenter\", \"object\"], ry.OT.eq)\n",
    "# komo.addObjective([1.], ry.FS.scalarProductZZ, [\"L_gripperCenter\", \"object\"], ry.OT.eq, target=[1])\n",
    "\n",
    "# komo.addObjective(time=[1.], feature=ry.FS.qItself, type=ry.OT.eq, order=1);\n",
    "# komo.optimize(True)\n",
    "# komo.getReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "tau = .01\n",
    "\n",
    "for t in range(300):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    #grab sensor readings from the simulation\n",
    "    q = S.get_q()\n",
    "    if t%10 == 0:\n",
    "        [rgb, depth] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "        points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "        #cameraFrame.setPointCloud(points, rgb)\n",
    "        bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
    "        circled_orig_blur = segment_ball(bgr)\n",
    "        \n",
    "        pc_coord = []\n",
    "        if circled_orig_blur is not None:\n",
    "            x,y = np.where(circled_orig_blur)\n",
    "            full_depth = np.zeros(points.shape)\n",
    "            for i, j in zip(x,y):\n",
    "                full_depth[i][j] = points[i][j] \n",
    "                pc_coord.append(points[i][j])\n",
    "            pc_coord =(np.array(pc_coord))\n",
    "            mean_pc = np.mean(pc_coord, axis=0)\n",
    "            cameraFrame.setPointCloud(full_depth, rgb)\n",
    "                    \n",
    "        V.recopyMeshes(C)\n",
    "        V.setConfiguration(C)\n",
    "        \n",
    "        #if len(depth)>0: cv.imshow('OPENCV - depth', 0.5* depth)\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "percept = C.addFrame(\"percept\", \"camera\")\n",
    "percept.setQuaternion([1,0,0,0])\n",
    "percept.setShape(ry.ST.sphere, [.03])\n",
    "percept.setColor([0,1,0])\n",
    "percept.setPosition(C.getFrame(\"camera\").getPosition()+list(mean_pc))\n",
    "V.setConfiguration(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y_GripCen, J_GripCen] = RealWorld.evalFeature(ry.FS.position, ['obj0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04764556,  0.08852315,  0.6785152 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_GripCen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1056515643144629"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pc_coord[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.063964  , 3.063964  , 3.063964  , ..., 3.063964  , 3.063964  ,\n",
       "        0.50000006],\n",
       "       [3.055892  , 3.055892  , 3.055892  , ..., 3.0543532 , 3.055892  ,\n",
       "        0.50000006],\n",
       "       [3.0478625 , 3.0478625 , 3.0478625 , ..., 3.0478625 , 3.0456824 ,\n",
       "        0.50000006],\n",
       "       ...,\n",
       "       [1.5769037 , 1.5769037 , 1.5769037 , ..., 1.0090779 , 1.0104021 ,\n",
       "        0.50000006],\n",
       "       [1.574763  , 1.574763  , 1.574763  , ..., 1.0073448 , 1.0082409 ,\n",
       "        0.50000006],\n",
       "       [0.50000006, 0.50000006, 0.50000006, ..., 0.50000006, 0.50000006,\n",
       "        0.50000006]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03785557, -0.30188178, -1.10565156])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "percept.setContact(1)\n",
    "R_gripper = C.frame(\"R_gripper\")\n",
    "L_gripper = C.frame(\"L_gripper\")\n",
    "R_gripper.setContact(1)\n",
    "#L_gripper.setContact(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x_dim': 320, 'T': 20, 'k_order': 2, 'tau': 0.25, 'useSwift': True},\n",
       " {'order': 2.0,\n",
       "  'type': 'sos',\n",
       "  'feature': 'qItself#32',\n",
       "  'vars': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'sos_sumOfSqr': 4.685238063308514},\n",
       " {'order': 0.0,\n",
       "  'type': 'ineq',\n",
       "  'feature': 'ProxyCost',\n",
       "  'vars': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'inEq_sumOfPos': 14.933640894546556},\n",
       " {'order': 0.0,\n",
       "  'type': 'sos',\n",
       "  'feature': 'Default-0-posDiff-R_gripperCenter-percept',\n",
       "  'vars': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  'sos_sumOfSqr': 0.004145420291314755},\n",
       " {'order': 0.0,\n",
       "  'type': 'sos',\n",
       "  'feature': 'Default-0-posDiff-R_gripperCenter-percept',\n",
       "  'vars': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  'sos_sumOfSqr': 0.004145420291314755},\n",
       " {'order': 0.0,\n",
       "  'type': 'eq',\n",
       "  'feature': 'Default-0-vecAlign-percept-R_gripperCenter',\n",
       "  'vars': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  'eq_sumOfAbs': 0.1884460950300224},\n",
       " {'order': 0.0,\n",
       "  'type': 'eq',\n",
       "  'feature': 'Default-0-vecAlign-R_gripperCenter-percept',\n",
       "  'vars': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  'eq_sumOfAbs': 0.24088043110854623},\n",
       " {'order': 1.0,\n",
       "  'type': 'eq',\n",
       "  'feature': 'qItself-ALL',\n",
       "  'vars': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  'eq_sumOfAbs': 2.557943014757026}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komo = C.komo_path(1.,20, 5., True) \n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.ineq, [1e2])\n",
    "\n",
    "komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripperCenter\", \"percept\"], ry.OT.sos, [1e3])\n",
    "\n",
    "\n",
    "komo.addObjective([1.], ry.FS.positionDiff, [\"R_gripperCenter\", \"percept\"], ry.OT.sos, [1e3])\n",
    "\n",
    "komo.addObjective([1.], ry.FS.scalarProductXZ, [\"percept\", \"R_gripperCenter\"], ry.OT.eq)\n",
    "komo.addObjective([1.], ry.FS.scalarProductXZ, [\"R_gripperCenter\", \"percept\"], ry.OT.eq)\n",
    "\n",
    "\n",
    "\n",
    "komo.addObjective(time=[1.], feature=ry.FS.qItself, type=ry.OT.eq, order=1);\n",
    "komo.optimize(True)\n",
    "komo.getReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = komo.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.playVideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.getGripperIsGrasping(\"R_gripper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.closeGripper(\"R_gripper\")\n",
    "S.steap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.openGripper(\"R_gripper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = S.get_q()\n",
    "S.openGripper(\"R_gripper\")\n",
    "S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "V=0\n",
    "S=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
